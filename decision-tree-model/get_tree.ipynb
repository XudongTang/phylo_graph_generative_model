{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "23dc577f-f6f6-4f3a-bc57-0d5471690a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import ete3\n",
    "import torch\n",
    "from ete3 import Tree\n",
    "import numpy as np\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e41bc33c-a167-4d0c-b7bb-52c1d1fa47f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert string to numbers\n",
    "def convert_string_to_numbers(str, dict):\n",
    "    ''' str: string to convert\n",
    "        dict dictionary with the relative ordering of each char'''\n",
    "            # create a map iterator using a lambda function\n",
    "    # lambda x -> return dict[x]\n",
    "    # This return the value for each key in dict based on str\n",
    "    numbers = map(lambda x: dict[x], str)\n",
    "    # return an array of int64 numbers\n",
    "    return np.fromiter(numbers, dtype=np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202d0015-cba9-4cea-833b-b4f39026e62d",
   "metadata": {},
   "source": [
    "## IndSeq structure\n",
    "### `name`\n",
    "The name of this species, the original species have name `1` to `n`, the internal species have name `n+t`\n",
    "### `seq`\n",
    "The sequence alignment of the species. The ancestral species have sequences generated from the children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "36dfabe5-2227-4e04-a50c-88d1f998072c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndSeq():\n",
    "    def __init__(self, name, seq):\n",
    "        self.name = name\n",
    "        self.seq = seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66248be8-18ec-45d6-b581-cd5980804110",
   "metadata": {},
   "source": [
    "## NNTree Structure\n",
    "\n",
    "### `Sequences`\n",
    "a list of `n-2` lists of `IndSeq` objects. Each list of `IndSeq` contains all IndSeq for each level, so it starts with `n`, and have `n-1` for each level beyond. For validation set, only the first level is included.\n",
    "### `n_node`\n",
    "number of species contained in the tree, this also includes number of levels for the rooted tree.\n",
    "### `level`\n",
    "a list of `n_node-2` numbered lists, each numbered list include two 1s and 0s for the rest. 1 indicate that the 2 nodes are being connected to the common ancester in the next level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "13e75543-99b2-4a98-b590-6a670a579ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNTree:\n",
    "    def __init__(self, n_node, IndSeq, level):\n",
    "        self.sequences = IndSeq\n",
    "        self.n_node = n_node\n",
    "        self.level = level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "491dcaf0-6af0-48cd-a8f8-d860d77d6d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_train_set(tree, seq_string, num_taxon):\n",
    "    # First we construct the sequence list of the first layer\n",
    "    seq_list = []                      # The sequences in one level\n",
    "    Sequences = []                      # The lists of sequence list for all levels\n",
    "    all_level = []                      # list\n",
    "    for i in range(len(seq_string)):\n",
    "        new_seq = IndSeq(str(i+1), convert_string_to_numbers(seq_string[i][:-1], dict_amino))\n",
    "        seq_list.append(new_seq)\n",
    "    # Now there are five IndSeq objects in the seq_list, we append it to the grand list\n",
    "    # Now we traverse the tree and construct internal nodes while getting new levels\n",
    "    # We need to give name to internal node by incrementing number\n",
    "    node_so_far = num_taxon\n",
    "    # The current level, start with 0\n",
    "    level = 0\n",
    "    for node in tree.traverse(\"postorder\"):\n",
    "        # This is when we found an internal node\n",
    "        # every time a internal node is found, we construct a new level\n",
    "        if node.name == \"\":\n",
    "            list_to_append = copy.deepcopy(seq_list)\n",
    "            Sequences.append(list_to_append)\n",
    "            # the individual level array, decrease by 1 for each level\n",
    "            ind_level = np.zeros(num_taxon - level)\n",
    "            # give name to the new node\n",
    "            node.name = str(node_so_far+1)\n",
    "            # increment the naming value\n",
    "            node_so_far += 1\n",
    "            # get all child of this internal node for getting the sequence\n",
    "            children = node.get_children()\n",
    "            left = children[0].name\n",
    "            right = children[1].name\n",
    "            \n",
    "            # Now we get the sequence of the internal node\n",
    "            # We also remove the child node from list of IndSeq\n",
    "            # We also need to get the index that changes to one\n",
    "            int_seq, ind_level, seq_list = internal_proc(left, right, seq_list, ind_level)\n",
    "            # we append the ind_level\n",
    "            all_level.append(ind_level)\n",
    "            # we add a new IndSeq object for the internal node\n",
    "            seq_list.append(IndSeq(node.name, int_seq))\n",
    "            level += 1\n",
    "    return NNTree(num_taxon, Sequences, all_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3457625a-8e97-4876-ad7e-06633db2f606",
   "metadata": {},
   "outputs": [],
   "source": [
    "def internal_proc(left, right, species_seq, ind_level):\n",
    "    #first we need to find the index of left and right child in the species_seq\n",
    "    # because we search by name\n",
    "    left_ind, right_ind = -1, -1\n",
    "    for i in range(len(species_seq)):\n",
    "        if species_seq[i].name == left:\n",
    "            left_ind = i\n",
    "        if species_seq[i].name == right:\n",
    "            right_ind = i\n",
    "        if left_ind != -1 and right_ind != -1:\n",
    "            break\n",
    "    # Now we obtain both left and right index\n",
    "    # First we generate the internal sequence\n",
    "    int_seq = []\n",
    "    for ii in range(len(species_seq[left_ind].seq)):\n",
    "        if species_seq[left_ind].seq[ii] == species_seq[right_ind].seq[ii]:\n",
    "            int_seq.append(species_seq[left_ind].seq[ii])\n",
    "        else:\n",
    "            int_seq.append(random.choice([species_seq[left_ind].seq[ii], species_seq[right_ind].seq[ii]]))\n",
    "    \n",
    "    # now we change the ind_level\n",
    "    ind_level[left_ind] = 1\n",
    "    ind_level[right_ind] = 1\n",
    "    \n",
    "    # now we remove the child IndSeq from the list\n",
    "    del species_seq[left_ind]\n",
    "    # since left is removed, we shift index to left by 1\n",
    "    del species_seq[right_ind - 1]\n",
    "\n",
    "    return int_seq, ind_level, species_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dab751-4a65-45d6-8f73-13f31972f19d",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fef331f1-d44f-44a6-b666-0195ee9b1308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "File proprocessing for 5-taxon trees\n",
      "------------------------------------------------------------------------\n",
      "Executing get_tree.py following model_param.json\n",
      "------------------------------------------------------------------------\n",
      "Loading Sequence Data in sequences12062021.in\n",
      "Loading Tree Data in trees12062021.in\n",
      "------------------------------------------------------------------------\n",
      "Number of samples: 10000\n"
     ]
    }
   ],
   "source": [
    "# get name of the script\n",
    "nameScript = \"get_tree.py\"\n",
    "# get json file name of the script\n",
    "nameJson = \"model_param.json\"\n",
    "\n",
    "print(\"------------------------------------------------------------------------\")\n",
    "print(\"File proprocessing for 5-taxon trees\")\n",
    "print(\"------------------------------------------------------------------------\")\n",
    "print(\"Executing \" + nameScript + \" following \" + nameJson, flush = True)\n",
    "\n",
    "# opening Json file \n",
    "jsonFile = open(nameJson) \n",
    "dataJson = json.load(jsonFile)\n",
    "\n",
    "data_root = dataJson[\"dataRoot\"]         # data folder\n",
    "model_root = dataJson[\"modelRoot\"]       # folder to save the data\n",
    "\n",
    "label_files = dataJson[\"labelFile\"]      # file with labels\n",
    "sequence_files = dataJson[\"matFile\"]     # file with sequences\n",
    "tree_files = dataJson[\"treeFile\"]        # file with tree structure\n",
    "num_taxon = dataJson[\"numTaxon\"]         # NUmber of taxon\n",
    "\n",
    "if \"summaryFile\" in dataJson:\n",
    "    summary_file = dataJson[\"summaryFile\"]\n",
    "else :\n",
    "    summary_file = \"summary_file.txt\"\n",
    "\n",
    "\n",
    "print(\"------------------------------------------------------------------------\") \n",
    "print(\"Loading Sequence Data in \" + sequence_files, flush = True)\n",
    "print(\"Loading Tree Data in \" + tree_files, flush = True)\n",
    "\n",
    "# we read the sequence as a list of strings\n",
    "with open(data_root+sequence_files, 'r') as f:\n",
    "    seq_string = f.readlines()\n",
    "\n",
    "with open(data_root+tree_files, 'r') as f:\n",
    "    tree_newick = f.readlines()\n",
    "seq_length = len(seq_string[0])-1\n",
    "num_sample = len(tree_newick)\n",
    "print(\"------------------------------------------------------------------------\") \n",
    "print(\"Number of samples: \" + str(num_sample), flush = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "67052150-a79a-484a-a367-665b54d2edb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "strL = \"\"\n",
    "for c in seq_string[0][:-1]:\n",
    "    if not c in strL:\n",
    "        strL += c\n",
    "\n",
    "# we sort them\n",
    "strL = sorted(strL)\n",
    "\n",
    "# we give them a relative order\n",
    "dict_amino = {}\n",
    "for ii, c in enumerate(strL):\n",
    "    dict_amino[c] = ii"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4867d3c2-f09a-4100-a5c1-6c69ffbbe375",
   "metadata": {},
   "source": [
    "## Construct the sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2950d53a-72d6-42a7-8663-d8343ce4ac13",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = [], []\n",
    "for i in range(int(num_sample*0.9)):\n",
    "    new_tree = construct_train_set(Tree(tree_newick[i]), seq_string[i*5:(i+1)*5], num_taxon)\n",
    "    train_set.append(new_tree)\n",
    "for ii in range(int(num_sample*0.9), int(num_sample*0.95)):\n",
    "    new_tree = construct_train_set(Tree(tree_newick[ii]), seq_string[ii*5:(ii+1)*5], num_taxon)\n",
    "    test_set.append(new_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1089285-3829-49d8-af12-487c133ddc5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "802488ee-967f-436c-808c-00a4b49eaca0",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5a815645-d88e-4899-b2aa-2b711c1e9b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetModule(torch.nn.Module):\n",
    "    '''Dense Residual network acting on each site, thus\n",
    "    implemtented via a Conv1 with window size equals to one\n",
    "    '''\n",
    "\n",
    "    def __init__(self, channel_count):\n",
    "        super().__init__()\n",
    "        self.layers = torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(channel_count, channel_count, 1),\n",
    "            torch.nn.BatchNorm1d(channel_count),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv1d(channel_count, channel_count, 1),\n",
    "            torch.nn.BatchNorm1d(channel_count),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a1e75e-9236-4747-94b2-967582fc04b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8024a8c1-7616-47f2-b89b-2ed072d2832d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceModule(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, length_dict, embed_dim, level):\n",
    "        super().__init__()\n",
    "        self.embedding_layer = nn.Embedding(length_dict, embedding_dim)\n",
    "        self._res_module_1 = ResNetModule(embedding_dim)\n",
    "        self._res_module_2 = ResNetModule(embedding_dim)\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.level = level\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding_layer(x).permute([0, 1, 3, 2])\n",
    "        d = []\n",
    "        # FIXME\n",
    "        # Change later, only first level for now!\n",
    "        d0 = self._res_module_1(x[:, 0, :, :])\n",
    "        d1 = self._res_module_1(x[:, 1, :, :])\n",
    "        d2 = self._res_module_1(x[:, 2, :, :])\n",
    "        d3 = self._res_module_1(x[:, 3, :, :])\n",
    "        d4 = self._res_module_1(x[:, 4, :, :])\n",
    "\n",
    "        aggregated_sum = self._res_module_2(d0+d1+d2+d3+d4)\n",
    "\n",
    "        D_0 = d0 + aggregated_sum\n",
    "        D_1 = d1 + aggregated_sum\n",
    "        D_2 = d2 + aggregated_sum\n",
    "        D_3 = d3 + aggregated_sum\n",
    "        D_4 = d4 + aggregated_sum\n",
    "\n",
    "        x = torch.cat([torch.unsequeeze(D_0, 1), \n",
    "                       torch.unsequeeze(D_1, 1),\n",
    "                       torch.unsequeeze(D_2, 1),\n",
    "                       torch.unsequeeze(D_3, 1),\n",
    "                       torch.unsequeeze(D_4, 1)], dim = 1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f9ca2dd1-e241-4335-9135-af48d8b1f2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class targetModule(torch.nn.Module):\n",
    "    def __init__(self, embed_dim, level, num_layers = 3, output_size = 20, dropout=0.0):\n",
    "        super().__init__()\n",
    "\n",
    "        self.sequence_model = SequenceModule(20, embed_dim, 0)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_size = output_size\n",
    "        self.embed_dim = embed_dim\n",
    "        self.fc = torch.nn.Linear(hidden_dim, self.output_size)\n",
    "\n",
    "        self.classifier = torch.nn.Linear(self.output_size, 1)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim,\n",
    "                           num_layers, dropout=dropout,\n",
    "                           batch_first=True)\n",
    "        self.rnn.flatten_parameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        device = x.device\n",
    "        batch_size = x.size()[0]\n",
    "\n",
    "        g = sequence_model(x)\n",
    "        X =  g.view(5*batch_size, self.embed_dim, -1)\n",
    "        r_output, hidden = self.rnn(X.permute([0, 2, 1]))\n",
    "        r_output_last = r_output[:, -1, :]\n",
    "        \n",
    "        out = r_output_last.contiguous().view(-1, self.hidden_dim)\n",
    "\n",
    "        # (none*3, out_put_dimensions)\n",
    "        output = self.fc(out)\n",
    "\n",
    "        X_combined = self.classifier(output)\n",
    "        # (3*none, 1)\n",
    "\n",
    "        X_combined = X_combined.view(batch_size, 5)\n",
    "\n",
    "        return X_combined\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1718164c-aeb5-4aef-919a-c22b0de3e827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 1.])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[0].level[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9688477-acd4-4e39-8423-003c680e446a",
   "metadata": {},
   "source": [
    "# Only the first layer for now!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "236f1787-9543-4e75-875a-3ba6c3595a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq = np.zeros((len(train_set)*num_taxon, seq_length), dtype=np.int64)\n",
    "train_label = np.zeros((len(train_set), num_taxon), dtype=np.int64)\n",
    "for i in range(len(train_set)):\n",
    "    train_label[i,:] = train_set[i].level[0]\n",
    "    for ii in range(len(train_set[i].sequences[0])):\n",
    "        train_seq[ii,:] = train_set[i].sequences[0][ii].seq.reshape((1, seq_length))\n",
    "train_seq = train_seq.reshape((len(train_set), -1, seq_length))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d814bb10-5a03-47a2-8b42-cb441200f481",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
